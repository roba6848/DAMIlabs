{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello! This lab has an objective to teach how to run simple classification models, mainly using the scikit-learn library. In this lab, you will learn how to build the models on a given training set and then apply them for predicting the values on a test set. Here in this lab we will also show you how to derive accuracy, one of the most famous performance measures, on the test set. This lab contains the extra tasks to practice **after** completing the labs with videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3-3. Run more algorithms using scikit-learn\n",
    "  - Adaboost\n",
    "  - Logistic regression\n",
    "\n",
    "- 3-4. Plotting the classifiers using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. Run more algorithms using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now it's your turn. You will try two more scikit-learn classifiers: **Adaboost, Logistic Regression**. Throughout this section, you will use the same training and test dataset we prepared above in the lab session! If you want to create it again, you can run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv(\"sonar.all-data\", header=None)\n",
    "X = data.drop(60, axis=1)\n",
    "y = data[60]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name suggests, **Adaboost** is a kind of boosting algorithm. Therefore, it is greatly influenced by 1) the base classifier, 2) how many classifiers are ensembled, and 3) how much learning rate is given. The boosting algorithm is a technique that ensures high variance by combining weak learners with high bias. Scikit-learn has a decision tree with a height of 1 as the default classifier, but you can change it to a more complex classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: You need to import the classifier from the library. You can find it from **ensemble** package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: You need to create an instance by calling the class. In this stage, you need to specify your options. Do not forget to put our value `RANDOM_SEED` to random_state parameter to get the result that can be validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Now, you need to fit your training data into the model! You can run *fit* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: You can finally test your model by calling *score* function with your test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not a graded assignment, but try to make the classifier having test accuracy more than 85%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is somewhat similar to a standard regression, but it is used to solve the classification problem. As logistic regression has many solvers, scikit-learn provides various options to choose, but the performance is not that much different. You can modify penalty (regularization), and inverse regularization factor C (the same one as SVC) to increase the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: You need to import the classifier from the library. You can find it from the **linear_model** package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: You need to create an instance by calling the class. In this stage, you need to specify your options. Let's try to use different C values, and also different solvers, and different regularization strategies (penalty) if you want. Detailed information can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Now, you need to fit your training data into the model! You can run *fit* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: You can finally test your model by calling *score* function with your test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not a graded assignment, but try to make the classifier having test accuracy more than 80%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Plotting the classifiers using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to make a nice plotting function that can represent our decision boundary. For this task, we do not require you to write all functions from scratch. Here we already made some skeleton function, and you can try to fill in the blanks to complete the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary(X, y, model, **params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Step 1: Choose only two columns we want to train and plot.\n",
    "    Step 2: Create an instance of the model with given parameters (params).\n",
    "    Step 3: Fit the model with two chosen columns.\n",
    "    Step 4: You should specify the boundaty of the plot (minimum/maximum value of each axis).\n",
    "    \"\"\"\n",
    "    # Configuration: You can ignore it!\n",
    "    h = .01\n",
    "    \n",
    "    # Step 1: Select two columns that you want to use.\n",
    "    reduced_data = None # CHANGE IT\n",
    "    \n",
    "    # Step 2 \n",
    "    m = None # CHANGE IT\n",
    "    \n",
    "    # Step 3\n",
    "    m.fit(None, None) # CHANGE IT\n",
    "    \n",
    "    # Step 4\n",
    "    x1_min = None # CHANGE IT\n",
    "    x1_max = None # CHANGE IT\n",
    "    x2_min = None # CHANGE IT\n",
    "    x2_max = None # CHANGE IT\n",
    "    \n",
    "    # This function makes a 2D matrix by receiving minimum/maximum values of each axis and a step value (h)\n",
    "    # meaning the distance between the previous value and the current value for each step.\n",
    "    xx, yy = np.meshgrid(np.arange(x1_min, x1_max, h), np.arange(x2_min, x2_max, h))\n",
    "    \n",
    "    # We predict the value by putting the combination of two attributes. \n",
    "    # We already made a working code for this job.\n",
    "    z = m.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    # Change the shape of the result\n",
    "    z = z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot configuration: You can ignore it!\n",
    "    plt.figure()\n",
    "    ## For plotting the area.\n",
    "    plt.contourf(xx, yy, z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ## For plotting the data points.\n",
    "    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "    ## For representing the axis.\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the iris dataset to test from the scikit-learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function, we can try plotting some decision boundaries of classifiers such as logistic regression or support vector machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "decision_boundary(X_iris, y_iris, LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "decision_boundary(X_iris, y_iris, SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This extra task is not graded. Try it with your own classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of practice assignment 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
